[![index](detectedai/detectedai/tree/main/static/images/screen.png)

ğŸ¯ Project Overview
This project aims to detect faces, recognize emotions, and identify body positions from images or videos. Leveraging advanced computer vision and deep learning techniques, the system can analyze and interpret human expressions and body language in real-time or from pre-recorded media.

ğŸ“‹ Features
Face Detection:
Accurately detects human faces in images or videos.
Supports multiple faces in a single frame.
ğŸ˜Š
Emotion Recognition:

Identifies emotions such as happiness, sadness, anger, surprise, and neutrality.
Provides probability scores for each detected emotion.

ğŸ‘¨â€ğŸ’¼ğŸ‘©â€ğŸ’¼
Body Detection:

Detects and maps key points on the human body (e.g., head, shoulders, arms, legs).
Provides pose estimation for activity tracking.

Real-Time Processing:

Processes live video streams for real-time analysis.
Optimized for webcam and video input.
ğŸ“‚ Project Structure
/models: Pretrained deep learning models for face, emotion, and body detection.
/data: Sample images and videos for testing.
/src: Core implementation scripts.
/outputs: Processed results, including annotated images and analysis logs.


ğŸ“‹ Requirements
To run this project, ensure the following dependencies are installed:

Python 3.11.8

pip install -r requirements.txt

git clone https://github.com/detectedai/detectedai.git
cd face-emotion-body-detection

python src/demo.py --input path_to_image_or_video


python src/demo.py --input data/sample_image.jpg


ğŸ§ª Examples
Input:

Output:

Detected face(s) with bounding boxes.
Emotion labels with confidence scores.
Body key points annotated on the image.


ğŸ¤ Contribute
We welcome contributions! If you'd like to add features, fix bugs, or improve documentation, feel free to fork the repository and submit a pull request.

ğŸ“¬ Contact
For questions or issues, please open a GitHub issue or contact the maintainers.
